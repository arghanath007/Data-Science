{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming_AND_Lemmatization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7vGR9boLGnpW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming with NLTK\n",
        "\n",
        "> Stemming just applies a bunch of fixed rules and it is kinda basic but it has some value when creating an NLP model."
      ],
      "metadata": {
        "id": "b3psrjb1aBSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer= PorterStemmer()"
      ],
      "metadata": {
        "id": "0sATUB3rZrcE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"|\", stemmer.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEs74OwoZzu7",
        "outputId": "f8efd62c-cf86-4a1b-ee2a-4fbb3bdb13fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization in spacy\n",
        "\n",
        "> This is more advanced and sophisticated than ' as it knows the given language rules and working so it can better convert the words into their base words."
      ],
      "metadata": {
        "id": "9mr1FvoZZ9z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp= spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_, \" | \", token.lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW-iW-XNaLba",
        "outputId": "1f75cdbc-1485-4aaa-e77d-1babfa9e2e4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eating  |  12092082220177030354\n",
            "eats  |  eat  |  9837207709914848172\n",
            "eat  |  eat  |  9837207709914848172\n",
            "ate  |  eat  |  9837207709914848172\n",
            "adjustable  |  adjustable  |  6033511944150694480\n",
            "rafting  |  raft  |  7154368781129989833\n",
            "ability  |  ability  |  11565809527369121409\n",
            "meeting  |  meet  |  6880656908171229526\n",
            "better  |  well  |  4525988469032889948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing talkative\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_, \" | \", token.lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JcQkNMAaQBW",
        "outputId": "c064a47e-58cd-48fe-ad2f-25943db6f1d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mando  |  Mando  |  7837215228004622142\n",
            "talked  |  talk  |  13939146775466599234\n",
            "for  |  for  |  16037325823156266367\n",
            "3  |  3  |  602994839685422785\n",
            "hours  |  hour  |  9748623380567160636\n",
            "although  |  although  |  343236316598008647\n",
            "talking  |  talk  |  13939146775466599234\n",
            "is  |  be  |  10382539506755952630\n",
            "n't  |  not  |  447765159362469301\n",
            "his  |  his  |  2661093235354845946\n",
            "thing  |  thing  |  2473243759842082748\n",
            "talkative  |  talkative  |  13364764166055324990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZNsd3axc9xc",
        "outputId": "602861c9-81b0-4e8a-9755-62e131407b77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### attribute_ruler\n",
        "\n",
        "> This components helps to customize the lemmas that are generated by the pretrained pipeline like below"
      ],
      "metadata": {
        "id": "CARJ5ROhdQml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar= nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, \" | \", token.lemma_, \" | \", token.lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8MUHTfreaFS",
        "outputId": "53ca5296-dcc4-4c6e-d33c-9472946f0124"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  Brother  |  4347558510128575363\n",
            ",  |  ,  |  2593208677638477497\n",
            "you  |  you  |  7624161793554793053\n",
            "wanna  |  wanna  |  13000462173222681081\n",
            "go  |  go  |  8004577259940138793\n",
            "?  |  ?  |  8205403955989537350\n",
            "Brah  |  Brother  |  4347558510128575363\n",
            ",  |  ,  |  2593208677638477497\n",
            "do  |  do  |  2158845516055552166\n",
            "n't  |  not  |  447765159362469301\n",
            "say  |  say  |  8685289367999165211\n",
            "no  |  no  |  13055779130471031426\n",
            "!  |  !  |  17494803046312582752\n",
            "I  |  I  |  4690420944186131903\n",
            "am  |  be  |  10382539506755952630\n",
            "exhausted  |  exhaust  |  5738807065439247694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaaAdDmge4Km",
        "outputId": "9b8f7b77-3c0a-4234-e2c1-3808c45d3db3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bro"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0].lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DagaDSWRfQPF",
        "outputId": "6fae1170-2374-428f-9a9d-2fc3443de8c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4347558510128575363"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0].lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "paQ1J03-fR71",
        "outputId": "90522b65-c2b5-4be8-a52d-8b8480ffece9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sEiAy5bafUPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}